"use strict";(self.webpackChunkmongodb_rag_docs=self.webpackChunkmongodb_rag_docs||[]).push([[787],{1155:function(e,n,i){i.r(n),i.d(n,{assets:function(){return a},contentTitle:function(){return c},default:function(){return h},frontMatter:function(){return o},metadata:function(){return r},toc:function(){return l}});var r=JSON.parse('{"id":"workshop/production-deployment/production-deployment","title":"\ud83d\udc50 Production Deployment","description":"In this final section, we\'ll cover best practices for deploying your MongoDB-RAG application to production, including optimization, monitoring, and scaling strategies.","source":"@site/docs/workshop/70-production-deployment/1-introduction.mdx","sourceDirName":"workshop/70-production-deployment","slug":"/workshop/production-deployment/production-deployment","permalink":"/mongodb-rag/docs/workshop/production-deployment/production-deployment","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/mongodb-rag/tree/main/mongodb-rag-docs/docs/workshop/70-production-deployment/1-introduction.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"production-deployment","title":"\ud83d\udc50 Production Deployment"},"sidebar":"docs","previous":{"title":"4 Query Expansion","permalink":"/mongodb-rag/docs/workshop/advanced-techniques/4-query-expansion"},"next":{"title":"2 Scaling","permalink":"/mongodb-rag/docs/workshop/production-deployment/2-scaling"}}'),s=i(4848),t=i(8453);const o={id:"production-deployment",title:"\ud83d\udc50 Production Deployment"},c="Deploying Your RAG Application to Production",a={},l=[{value:"Architecture Considerations",id:"architecture-considerations",level:2},{value:"Microservices Approach",id:"microservices-approach",level:3},{value:"Optimizing MongoDB Atlas",id:"optimizing-mongodb-atlas",level:2},{value:"Sizing and Scaling",id:"sizing-and-scaling",level:3},{value:"Index Optimization",id:"index-optimization",level:3},{value:"Connection Pooling",id:"connection-pooling",level:3},{value:"Caching Strategies",id:"caching-strategies",level:2},{value:"Query Result Caching",id:"query-result-caching",level:3},{value:"Embedding Caching",id:"embedding-caching",level:3},{value:"LLM Response Caching",id:"llm-response-caching",level:3},{value:"Rate Limiting and Queueing",id:"rate-limiting-and-queueing",level:2},{value:"Rate Limiting",id:"rate-limiting",level:3},{value:"Job Queueing",id:"job-queueing",level:3},{value:"Monitoring and Observability",id:"monitoring-and-observability",level:2},{value:"Prometheus Metrics",id:"prometheus-metrics",level:3},{value:"Logging",id:"logging",level:3},{value:"Deployment Options",id:"deployment-options",level:2},{value:"Docker Containerization",id:"docker-containerization",level:3},{value:"Kubernetes Deployment",id:"kubernetes-deployment",level:3},{value:"Security Considerations",id:"security-considerations",level:2},{value:"API Key Management",id:"api-key-management",level:3},{value:"MongoDB Atlas Security",id:"mongodb-atlas-security",level:3},{value:"Cost Optimization",id:"cost-optimization",level:2},{value:"Embedding Generation Cost",id:"embedding-generation-cost",level:3},{value:"LLM Usage Optimization",id:"llm-usage-optimization",level:3},{value:"Continuous Improvement",id:"continuous-improvement",level:2},{value:"A/B Testing Framework",id:"ab-testing-framework",level:3},{value:"Feedback Collection",id:"feedback-collection",level:3},{value:"Conclusion",id:"conclusion",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"deploying-your-rag-application-to-production",children:"Deploying Your RAG Application to Production"})}),"\n",(0,s.jsx)(n.p,{children:"In this final section, we'll cover best practices for deploying your MongoDB-RAG application to production, including optimization, monitoring, and scaling strategies."}),"\n",(0,s.jsx)(n.h2,{id:"architecture-considerations",children:"Architecture Considerations"}),"\n",(0,s.jsx)(n.p,{children:"When deploying a RAG application to production, consider this reference architecture:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502     \u2502                 \u2502     \u2502                 \u2502\n\u2502  Document       \u2502     \u2502  Search         \u2502     \u2502  LLM            \u2502\n\u2502  Processing     \u2502\u25c4\u2500\u2500\u2500\u2500\u2524  Service        \u2502\u25c4\u2500\u2500\u2500\u2500\u2524  Service        \u2502\n\u2502  Service        \u2502     \u2502                 \u2502     \u2502                 \u2502\n\u2502                 \u2502     \u2502                 \u2502     \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u25bc                       \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502     \u2502                 \u2502     \u2502                 \u2502\n\u2502  MongoDB Atlas  \u2502     \u2502  Cache          \u2502     \u2502  LLM Provider   \u2502\n\u2502  (Vector Store) \u2502     \u2502  (Redis/Memcached)    \u2502  (OpenAI/etc.)  \u2502\n\u2502                 \u2502     \u2502                 \u2502     \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h3,{id:"microservices-approach",children:"Microservices Approach"}),"\n",(0,s.jsx)(n.p,{children:"Consider splitting your application into specialized microservices:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Document Processing Service"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Handles document ingestion, chunking, and embedding generation"}),"\n",(0,s.jsx)(n.li,{children:"Manages the document ingestion pipeline"}),"\n",(0,s.jsx)(n.li,{children:"Processes documents asynchronously with a queue"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Search Service"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Manages vector search and retrieval"}),"\n",(0,s.jsx)(n.li,{children:"Implements hybrid search capabilities"}),"\n",(0,s.jsx)(n.li,{children:"Caches common search results"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"LLM Service"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Handles prompt construction and LLM interaction"}),"\n",(0,s.jsx)(n.li,{children:"Manages prompt templates and response generation"}),"\n",(0,s.jsx)(n.li,{children:"Implements retry logic and fallback mechanisms"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"optimizing-mongodb-atlas",children:"Optimizing MongoDB Atlas"}),"\n",(0,s.jsx)(n.h3,{id:"sizing-and-scaling",children:"Sizing and Scaling"}),"\n",(0,s.jsx)(n.p,{children:"For production deployments, ensure your MongoDB Atlas cluster is properly sized:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Cluster Tier Selection"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"M10+ for small production workloads"}),"\n",(0,s.jsx)(n.li,{children:"M30+ for medium-sized applications"}),"\n",(0,s.jsx)(n.li,{children:"M60+ for larger workloads with high query volumes"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Horizontal Scaling"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use sharding for very large vector collections (billions of vectors)"}),"\n",(0,s.jsx)(n.li,{children:"Distribute data across multiple shards based on a shard key"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Instance Size"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ensure sufficient RAM for vector search operations"}),"\n",(0,s.jsx)(n.li,{children:"Consider storage requirements for documents and embeddings"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"index-optimization",children:"Index Optimization"}),"\n",(0,s.jsx)(n.p,{children:"Optimize your vector search indexes:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:'const optimizedIndex = {\n  name: "production_vector_index",\n  type: "vectorSearch",\n  definition: {\n    fields: [\n      {\n        type: "vector",\n        path: "embedding",\n        numDimensions: 1536,\n        similarity: "cosine",\n        quantization: {\n          type: "scalar",\n          config: {\n            components: { type: "int8" }  // Quantize for better performance\n          }\n        }\n      }\n    ],\n    indexedFields: [\n      "metadata.source",\n      "metadata.type",\n      "metadata.created"\n    ],\n    preImageStorage: {\n      enabled: false  // Disable for better space utilization\n    }\n  }\n};\n'})}),"\n",(0,s.jsx)(n.h3,{id:"connection-pooling",children:"Connection Pooling"}),"\n",(0,s.jsx)(n.p,{children:"Implement connection pooling for efficient database connections:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// In your MongoDB connection configuration\nconst client = new MongoClient(uri, {\n  maxPoolSize: 50,              // Adjust based on expected concurrency\n  minPoolSize: 5,               // Maintain minimum connections\n  maxIdleTimeMS: 30000,         // Close idle connections after 30 seconds\n  waitQueueTimeoutMS: 10000,    // Timeout for waiting for connection\n  connectTimeoutMS: 30000,      // Timeout for initial connection\n  socketTimeoutMS: 45000        // Timeout for socket operations\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"caching-strategies",children:"Caching Strategies"}),"\n",(0,s.jsx)(n.p,{children:"Implement multi-level caching to improve performance:"}),"\n",(0,s.jsx)(n.h3,{id:"query-result-caching",children:"Query Result Caching"}),"\n",(0,s.jsx)(n.p,{children:"Cache common search results:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const NodeCache = require('node-cache');\nconst cache = new NodeCache({ stdTTL: 3600, checkperiod: 120 });\n\nasync function cachedSearch(query, options = {}) {\n  // Generate cache key based on query and options\n  const cacheKey = `search:${JSON.stringify({query, options})}`;\n  \n  // Check cache first\n  const cachedResults = cache.get(cacheKey);\n  if (cachedResults) {\n    console.log('Cache hit for query:', query);\n    return cachedResults;\n  }\n  \n  // If not in cache, perform search\n  const results = await rag.search(query, options);\n  \n  // Cache the results\n  cache.set(cacheKey, results);\n  \n  return results;\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"embedding-caching",children:"Embedding Caching"}),"\n",(0,s.jsx)(n.p,{children:"Cache embeddings to avoid regenerating them:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const NodeCache = require('node-cache');\nconst embeddingCache = new NodeCache({ stdTTL: 86400, checkperiod: 600 });\n\n// Extend the embedding provider with caching\nclass CachedEmbeddingProvider {\n  constructor(provider) {\n    this.provider = provider;\n  }\n  \n  async getEmbedding(text) {\n    const cacheKey = `embed:${text}`;\n    \n    // Check cache first\n    const cachedEmbedding = embeddingCache.get(cacheKey);\n    if (cachedEmbedding) {\n      return cachedEmbedding;\n    }\n    \n    // Generate embedding if not cached\n    const embedding = await this.provider.getEmbedding(text);\n    \n    // Cache the embedding\n    embeddingCache.set(cacheKey, embedding);\n    \n    return embedding;\n  }\n  \n  async getEmbeddings(texts) {\n    // Implement batch caching logic\n    // ...\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"llm-response-caching",children:"LLM Response Caching"}),"\n",(0,s.jsx)(n.p,{children:"Cache LLM responses for repeating queries:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const NodeCache = require('node-cache');\nconst llmCache = new NodeCache({ stdTTL: 3600, checkperiod: 120 });\n\nasync function cachedLLMGeneration(messages, options = {}) {\n  // Generate cache key based on messages\n  const cacheKey = `llm:${JSON.stringify(messages)}`;\n  \n  // Check cache first\n  const cachedResponse = llmCache.get(cacheKey);\n  if (cachedResponse) {\n    return cachedResponse;\n  }\n  \n  // Generate response if not cached\n  const response = await openai.chat.completions.create({\n    model: options.model || config.llm.model,\n    messages,\n    temperature: options.temperature || 0.3\n  });\n  \n  // Cache the response\n  llmCache.set(cacheKey, response);\n  \n  return response;\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"rate-limiting-and-queueing",children:"Rate Limiting and Queueing"}),"\n",(0,s.jsx)(n.p,{children:"Implement rate limiting and job queueing for robust production applications:"}),"\n",(0,s.jsx)(n.h3,{id:"rate-limiting",children:"Rate Limiting"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const rateLimit = require('express-rate-limit');\nconst RedisStore = require('rate-limit-redis');\nconst Redis = require('ioredis');\n\nconst redis = new Redis(process.env.REDIS_URL);\n\n// Apply rate limiting middleware\napp.use('/api/rag', rateLimit({\n  store: new RedisStore({\n    sendCommand: (...args) => redis.call(...args)\n  }),\n  windowMs: 60 * 1000, // 1 minute\n  max: 20, // 20 requests per minute\n  standardHeaders: true,\n  message: {\n    error: 'Too many requests, please try again later.'\n  }\n}));\n"})}),"\n",(0,s.jsx)(n.h3,{id:"job-queueing",children:"Job Queueing"}),"\n",(0,s.jsx)(n.p,{children:"Use a job queue for background processing:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const { Queue, Worker } = require('bullmq');\nconst Redis = require('ioredis');\n\n// Create Redis connection\nconst connection = new Redis(process.env.REDIS_URL);\n\n// Create document processing queue\nconst documentQueue = new Queue('document-processing', { connection });\n\n// Add document to processing queue\nasync function queueDocumentForProcessing(document) {\n  await documentQueue.add('process-document', {\n    document,\n    timestamp: Date.now()\n  }, {\n    attempts: 3,\n    backoff: {\n      type: 'exponential',\n      delay: 5000\n    }\n  });\n  \n  return { status: 'queued', documentId: document.id };\n}\n\n// Process documents from queue\nconst processingWorker = new Worker('document-processing', async (job) => {\n  const { document } = job.data;\n  \n  try {\n    // Step 1: Chunk document\n    const chunks = await chunker.chunkDocument(document);\n    \n    // Step 2: Generate embeddings and store in MongoDB\n    const result = await rag.ingestBatch(chunks);\n    \n    return { processed: result.processed };\n  } catch (error) {\n    console.error('Document processing error:', error);\n    throw error;\n  }\n}, { connection });\n"})}),"\n",(0,s.jsx)(n.h2,{id:"monitoring-and-observability",children:"Monitoring and Observability"}),"\n",(0,s.jsx)(n.p,{children:"Implement comprehensive monitoring for your production RAG application:"}),"\n",(0,s.jsx)(n.h3,{id:"prometheus-metrics",children:"Prometheus Metrics"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const client = require('prom-client');\nconst register = new client.Registry();\n\n// Add default metrics\nclient.collectDefaultMetrics({ register });\n\n// Create custom metrics\nconst searchLatency = new client.Histogram({\n  name: 'rag_search_latency_seconds',\n  help: 'RAG search latency in seconds',\n  labelNames: ['status'],\n  buckets: [0.1, 0.5, 1, 2, 5, 10]\n});\n\nconst llmLatency = new client.Histogram({\n  name: 'llm_request_latency_seconds',\n  help: 'LLM request latency in seconds',\n  labelNames: ['model', 'status'],\n  buckets: [0.5, 1, 3, 5, 10, 30]\n});\n\nconst searchCounter = new client.Counter({\n  name: 'rag_search_total',\n  help: 'Total number of RAG searches',\n  labelNames: ['status']\n});\n\n// Register metrics\nregister.registerMetric(searchLatency);\nregister.registerMetric(llmLatency);\nregister.registerMetric(searchCounter);\n\n// Add metrics endpoint\napp.get('/metrics', async (req, res) => {\n  res.set('Content-Type', register.contentType);\n  res.end(await register.metrics());\n});\n\n// Instrument search function\nasync function instrumentedSearch(query, options = {}) {\n  const end = searchLatency.startTimer();\n  searchCounter.inc({ status: 'started' });\n  \n  try {\n    const results = await rag.search(query, options);\n    end({ status: 'success' });\n    searchCounter.inc({ status: 'success' });\n    return results;\n  } catch (error) {\n    end({ status: 'error' });\n    searchCounter.inc({ status: 'error' });\n    throw error;\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"logging",children:"Logging"}),"\n",(0,s.jsx)(n.p,{children:"Implement structured logging for better observability:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const winston = require('winston');\nconst { ElasticsearchTransport } = require('winston-elasticsearch');\n\n// Configure logger\nconst logger = winston.createLogger({\n  level: process.env.LOG_LEVEL || 'info',\n  format: winston.format.combine(\n    winston.format.timestamp(),\n    winston.format.json()\n  ),\n  defaultMeta: { service: 'rag-service' },\n  transports: [\n    new winston.transports.Console(),\n    new ElasticsearchTransport({\n      level: 'info',\n      clientOpts: { node: process.env.ELASTICSEARCH_URL },\n      indexPrefix: 'rag-logs'\n    })\n  ]\n});\n\n// Log search events\nasync function loggedSearch(query, options = {}) {\n  logger.info('Search initiated', {\n    query,\n    options,\n    userId: options.userId,\n    requestId: options.requestId\n  });\n  \n  try {\n    const results = await rag.search(query, options);\n    \n    logger.info('Search completed', {\n      query,\n      resultCount: results.length,\n      topScore: results[0]?.score,\n      durationMs: Date.now() - startTime,\n      requestId: options.requestId\n    });\n    \n    return results;\n  } catch (error) {\n    logger.error('Search failed', {\n      query,\n      error: error.message,\n      stack: error.stack,\n      requestId: options.requestId\n    });\n    \n    throw error;\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"deployment-options",children:"Deployment Options"}),"\n",(0,s.jsx)(n.h3,{id:"docker-containerization",children:"Docker Containerization"}),"\n",(0,s.jsxs)(n.p,{children:["Create a ",(0,s.jsx)(n.code,{children:"Dockerfile"})," for your application:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-dockerfile",children:'FROM node:18-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci --only=production\n\nCOPY . .\n\nENV NODE_ENV=production\nENV PORT=3000\n\nEXPOSE 3000\n\nCMD ["node", "src/index.js"]\n'})}),"\n",(0,s.jsx)(n.h3,{id:"kubernetes-deployment",children:"Kubernetes Deployment"}),"\n",(0,s.jsx)(n.p,{children:"Create a Kubernetes deployment manifest:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rag-application\n  labels:\n    app: rag-application\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: rag-application\n  template:\n    metadata:\n      labels:\n        app: rag-application\n    spec:\n      containers:\n      - name: rag-application\n        image: your-registry/rag-application:latest\n        ports:\n        - containerPort: 3000\n        env:\n        - name: MONGODB_URI\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-credentials\n              key: uri\n        - name: OPENAI_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: openai-credentials\n              key: api-key\n        resources:\n          requests:\n            memory: "512Mi"\n            cpu: "200m"\n          limits:\n            memory: "1Gi"\n            cpu: "500m"\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 3000\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3000\n          initialDelaySeconds: 20\n          periodSeconds: 15\n'})}),"\n",(0,s.jsx)(n.h2,{id:"security-considerations",children:"Security Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"api-key-management",children:"API Key Management"}),"\n",(0,s.jsx)(n.p,{children:"Use environment variables and secrets management:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// Load environment variables from a secure source\nrequire('dotenv').config();\n\n// Access keys securely\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY\n});\n\nconst rag = new MongoRAG({\n  mongoUrl: process.env.MONGODB_URI,\n  // ...other config\n  embedding: {\n    provider: process.env.EMBEDDING_PROVIDER,\n    apiKey: process.env.EMBEDDING_API_KEY\n  }\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"mongodb-atlas-security",children:"MongoDB Atlas Security"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Network Security"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use IP allowlists or private endpoints"}),"\n",(0,s.jsx)(n.li,{children:"Enable VPC peering for cloud deployments"}),"\n",(0,s.jsx)(n.li,{children:"Configure TLS/SSL for all connections"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Authentication"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use strong, unique passwords"}),"\n",(0,s.jsx)(n.li,{children:"Implement database users with least privilege"}),"\n",(0,s.jsx)(n.li,{children:"Consider SCRAM authentication"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Encryption"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Enable encryption at rest"}),"\n",(0,s.jsx)(n.li,{children:"Use TLS/SSL for data in transit"}),"\n",(0,s.jsx)(n.li,{children:"Consider client-side field level encryption for sensitive data"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"cost-optimization",children:"Cost Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"embedding-generation-cost",children:"Embedding Generation Cost"}),"\n",(0,s.jsx)(n.p,{children:"Optimize embedding generation costs:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Batch Processing"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Process documents in batches"}),"\n",(0,s.jsx)(n.li,{children:"Use the lowest-cost embedding model that meets quality requirements"}),"\n",(0,s.jsx)(n.li,{children:"Cache embeddings to avoid regeneration"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Selective Updates"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Only regenerate embeddings when content changes"}),"\n",(0,s.jsx)(n.li,{children:"Implement delta updates for document changes"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"llm-usage-optimization",children:"LLM Usage Optimization"}),"\n",(0,s.jsx)(n.p,{children:"Reduce LLM API costs:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Context Trimming"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Send only the most relevant context to the LLM"}),"\n",(0,s.jsx)(n.li,{children:"Implement intelligent context selection"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Response Caching"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Cache common LLM responses"}),"\n",(0,s.jsx)(n.li,{children:"Implement semantic caching based on query similarity"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Model Selection"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use smaller models for simpler tasks"}),"\n",(0,s.jsx)(n.li,{children:"Implement model cascading (try smaller models first)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"continuous-improvement",children:"Continuous Improvement"}),"\n",(0,s.jsx)(n.h3,{id:"ab-testing-framework",children:"A/B Testing Framework"}),"\n",(0,s.jsx)(n.p,{children:"Implement A/B testing to evaluate RAG improvements:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"async function abTestSearch(query, options = {}) {\n  // Determine which variant to use\n  const variant = Math.random() < 0.5 ? 'A' : 'B';\n  \n  // Execute the appropriate search method\n  let results;\n  const startTime = Date.now();\n  \n  if (variant === 'A') {\n    // Control: Standard search\n    results = await rag.search(query, options);\n  } else {\n    // Treatment: New search algorithm\n    results = await advancedSearch(query, options);\n  }\n  \n  // Record metrics\n  const duration = Date.now() - startTime;\n  \n  // Log experiment data\n  logger.info('Search experiment', {\n    variant,\n    query,\n    resultCount: results.length,\n    topScore: results[0]?.score,\n    duration,\n    experimentId: 'search-algorithm-v2'\n  });\n  \n  return results;\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"feedback-collection",children:"Feedback Collection"}),"\n",(0,s.jsx)(n.p,{children:"Implement user feedback collection:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"async function recordSearchFeedback(searchId, feedback) {\n  await feedbackCollection.insertOne({\n    searchId,\n    query: feedback.query,\n    results: feedback.results,\n    rating: feedback.rating,\n    comments: feedback.comments,\n    timestamp: new Date()\n  });\n  \n  // Track relevance metrics\n  if (feedback.rating >= 4) {\n    relevanceMetrics.inc({ status: 'good' });\n  } else if (feedback.rating <= 2) {\n    relevanceMetrics.inc({ status: 'poor' });\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsx)(n.p,{children:"Congratulations! You've completed the MongoDB-RAG Workshop. You now have the knowledge and skills to:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Set up MongoDB Atlas with Vector Search"}),"\n",(0,s.jsx)(n.li,{children:"Create and manage vector embeddings"}),"\n",(0,s.jsx)(n.li,{children:"Build a complete RAG application with MongoDB"}),"\n",(0,s.jsx)(n.li,{children:"Implement advanced retrieval techniques"}),"\n",(0,s.jsx)(n.li,{children:"Deploy and optimize your application for production"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(n.p,{children:"To continue your RAG journey:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Explore Advanced Features"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Try different embedding models"}),"\n",(0,s.jsx)(n.li,{children:"Experiment with hybrid search approaches"}),"\n",(0,s.jsx)(n.li,{children:"Implement multi-modal RAG (text, images, etc.)"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Integrate with Your Systems"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Connect your RAG system to your existing data sources"}),"\n",(0,s.jsx)(n.li,{children:"Build domain-specific knowledge bases"}),"\n",(0,s.jsx)(n.li,{children:"Implement custom workflows"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Stay Updated"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Follow the ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/developer/languages/javascript/",children:"MongoDB Developer Blog"})]}),"\n",(0,s.jsxs)(n.li,{children:["Join the ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/community/forums/",children:"MongoDB Community Forums"})]}),"\n",(0,s.jsx)(n.li,{children:"Check for updates to the mongodb-rag library"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"We hope you found this workshop valuable and look forward to seeing what you build with MongoDB-RAG!"})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:function(e,n,i){i.d(n,{R:function(){return o},x:function(){return c}});var r=i(6540);const s={},t=r.createContext(s);function o(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);