"use strict";(self.webpackChunkmongodb_rag_docs=self.webpackChunkmongodb_rag_docs||[]).push([[8280],{8356:function(n,e,t){t.r(e),t.d(e,{assets:function(){return c},contentTitle:function(){return i},default:function(){return d},frontMatter:function(){return a},metadata:function(){return r},toc:function(){return u}});var r=JSON.parse('{"id":"workshop/build-rag-app/5-cheat-script","title":"\ud83d\udee0\ufe0f Build Script","description":"Build Script","source":"@site/docs/workshop/50-build-rag-app/5-cheat-script.mdx","sourceDirName":"workshop/50-build-rag-app","slug":"/workshop/build-rag-app/5-cheat-script","permalink":"/mongodb-rag/docs/workshop/build-rag-app/5-cheat-script","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/mongodb-rag/tree/main/mongodb-rag-docs/docs/workshop/50-build-rag-app/5-cheat-script.mdx","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"5-cheat-script","title":"\ud83d\udee0\ufe0f Build Script"},"sidebar":"docs","previous":{"title":"4 Integrate Llm","permalink":"/mongodb-rag/docs/workshop/build-rag-app/4-integrate-llm"},"next":{"title":"1 Introduction","permalink":"/mongodb-rag/docs/workshop/advanced-techniques/1-introduction"}}'),o=t(4848),s=t(8453);const a={id:"5-cheat-script",title:"\ud83d\udee0\ufe0f Build Script"},i=void 0,c={},u=[{value:"Build Script",id:"build-script",level:2}];function l(n){const e={code:"code",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h2,{id:"build-script",children:"Build Script"}),"\n",(0,o.jsx)(e.p,{children:"Use this script to build the directory structure and populate some of the files you'll need to get started."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"#!/bin/bash\n\n# Create the directory structure\nmkdir -p rag-workshop/{data/articles,src/utils,tests}\n\n# Create package.json\ncat <<EOL > rag-workshop/package.json\n{\n  \"name\": \"rag-workshop\",\n  \"version\": \"1.0.0\",\n  \"description\": \"RAG application workshop with MongoDB Atlas\",\n  \"main\": \"src/index.js\",\n  \"scripts\": {\n    \"start\": \"node src/index.js\",\n    \"ingest\": \"node src/ingest.js\",\n    \"search\": \"node src/search.js\",\n    \"test\": \"jest\"\n  },\n  \"dependencies\": {\n    \"dotenv\": \"^16.3.1\",\n    \"express\": \"^4.18.2\",\n    \"mongodb-rag\": \"^0.53.0\",\n    \"openai\": \"^4.10.0\",\n    \"fs-extra\": \"^11.1.1\"\n  },\n  \"devDependencies\": {\n    \"jest\": \"^29.6.2\"\n  }\n}\nEOL\n\n# Create .env file\ncat <<EOL > rag-workshop/.env\nMONGODB_URI=your_mongodb_connection_string\nEMBEDDING_API_KEY=your_openai_api_key\nMONGODB_DATABASE_NAME=your_database_name\nMONGODB_COLLECTION_NAME=your_collection_name\nEOL\n\n# Create sample data files\ncat <<EOL > rag-workshop/data/articles/mongodb-atlas.md\n# MongoDB Atlas: The Cloud Database Service\n\nMongoDB Atlas is a fully-managed cloud database service developed by MongoDB. It handles all the complexity of deploying, managing, and healing your deployments on the cloud service provider of your choice (AWS, Azure, and GCP).\n\n## Key Features\n\n### Automated Deployment and Management\nMongoDB Atlas automates deployment, maintenance, and scaling. You can deploy a cluster with a few clicks or API calls.\n\n### Security\nMongoDB Atlas provides multiple layers of security for your database:\n- Network isolation with VPC peering\n- IP whitelisting\n- Advanced authentication\n- Field-level encryption\n- RBAC (Role-Based Access Control)\n- LDAP integration\n\n### Monitoring and Alerts\nThe service includes built-in monitoring tools and customizable alerts based on over a dozen different metrics.\n\n### Automated Backups\nContinuous backups with point-in-time recovery ensure your data is protected.\n\n### Scaling Options\nScale up or down without application downtime. Auto-scaling provisions storage capacity automatically.\n\n### Global Clusters\nCreate globally distributed clusters that route data to the closest available region to minimize latency.\n\n## Integrations\n\nMongoDB Atlas integrates with popular services and tools:\n- AWS services (Lambda, SageMaker, etc.)\n- Google Cloud (Firebase, DataFlow, etc.)\n- Microsoft Azure services\n- Kafka\n- Kubernetes\n\n## Atlas Vector Search\n\nMongoDB Atlas Vector Search enables you to build vector search applications by storing embeddings and performing k-nearest neighbor (k-NN) search.\n\nKey capabilities include:\n- Store vector embeddings along with your operational data\n- Build semantic search applications\n- Power recommendation engines\n- Implement AI-powered applications\nEOL\n\ncat <<EOL > rag-workshop/data/articles/rag-overview.md\n# Retrieval-Augmented Generation (RAG): An Overview\n\nRetrieval-Augmented Generation (RAG) is an AI framework that enhances large language models (LLMs) by retrieving relevant information from external knowledge sources to ground the model's responses in factual, up-to-date information.\n\n## How RAG Works\n\nThe RAG process typically consists of three main stages:\n\n1. **Retrieval**: The system queries a knowledge base to find information relevant to the input prompt\n2. **Augmentation**: Retrieved information is added to the context provided to the LLM\n3. **Generation**: The LLM generates a response based on both the prompt and the retrieved information\n\n## Benefits of RAG\n\nRetrieval-Augmented Generation offers several advantages:\n\n### Reduced Hallucinations\nBy grounding responses in retrieved facts, RAG significantly reduces the tendency of LLMs to generate plausible-sounding but incorrect information.\n\n### Up-to-date Information\nRAG systems can access recent information beyond the LLM's training cutoff date, keeping responses current.\n\n### Domain Specialization\nRAG enables general-purpose LLMs to provide expert-level responses in specialized domains by retrieving domain-specific information.\n\n### Transparency and Attribution\nInformation sources can be tracked and cited, improving transparency and trustworthiness.\n\n### Cost Efficiency\nRetrieving information can be more efficient than training ever-larger models to memorize more facts.\n\n## Implementation Considerations\n\nWhen implementing RAG, several factors must be considered:\n\n### Knowledge Base Design\nThe structure, format, and organization of the knowledge base significantly impact retrieval effectiveness.\n\n### Embedding Strategy\nHow documents are converted to vector embeddings affects search quality.\n\n### Chunking Approach\nThe method used to divide documents into chunks can impact retrieval precision.\n\n### Retrieval Algorithms\nDifferent retrieval methods (BM25, vector search, hybrid approaches) have varying effectiveness depending on the use case.\n\n### Context Window Management\nEfficiently using the LLM's context window is essential for complex queries requiring multiple retrieved documents.\n\n## Common Challenges\n\nRAG implementations often face several challenges:\n\n- Balancing retrieval precision and recall\n- Handling contradictory information from multiple sources\n- Managing context window limitations\n- Addressing retrieval latency in real-time applications\nEOL\n\ncat <<EOL > rag-workshop/data/qa-pairs.json\n[\n  {\n    \"question\": \"What is MongoDB Atlas?\",\n    \"expected_source\": \"mongodb-atlas.md\"\n  },\n  {\n    \"question\": \"What security features does MongoDB Atlas offer?\",\n    \"expected_source\": \"mongodb-atlas.md\"\n  },\n  {\n    \"question\": \"How does RAG reduce hallucinations?\",\n    \"expected_source\": \"rag-overview.md\"\n  },\n  {\n    \"question\": \"What are the three main stages of RAG?\",\n    \"expected_source\": \"rag-overview.md\"\n  },\n  {\n    \"question\": \"What is Atlas Vector Search used for?\",\n    \"expected_source\": \"mongodb-atlas.md\"\n  }\n]\nEOL\n\n# Create configuration file\ncat <<EOL > rag-workshop/src/config.js\nrequire('dotenv').config();\n\nmodule.exports = {\n  mongodb: {\n    uri: process.env.MONGODB_URI,\n    database: process.env.MONGODB_DATABASE_NAME,\n    collection: process.env.MONGODB_COLLECTION_NAME\n  },\n  embedding: {\n    provider: process.env.EMBEDDING_PROVIDER || 'openai',\n    apiKey: process.env.EMBEDDING_API_KEY,\n    model: process.env.EMBEDDING_MODEL || 'text-embedding-3-small',\n    dimensions: 1536\n  },\n  search: {\n    maxResults: 5,\n    minScore: 0.7,\n    returnSources: true\n  }\n};\nEOL\n\n# Create document ingestion script\ncat <<EOL > rag-workshop/src/ingest.js\nconst fs = require('fs-extra');\nconst path = require('path');\nconst { MongoRAG, Chunker } = require('mongodb-rag');\nconst config = require('./config');\n\n// Initialize MongoRAG\nconst rag = new MongoRAG({\n  mongoUrl: config.mongodb.uri,\n  database: config.mongodb.database,\n  collection: config.mongodb.collection,\n  embedding: config.embedding\n});\n\n// Create a chunker\nconst chunker = new Chunker({\n  strategy: config.chunking.strategy,\n  maxChunkSize: config.chunking.maxChunkSize,\n  overlap: config.chunking.overlap\n});\n\n// Function to read and process markdown files\nasync function ingestMarkdownFiles(directory) {\n  try {\n    // Get all markdown files\n    const files = await fs.readdir(directory);\n    const markdownFiles = files.filter(file => file.endsWith('.md'));\n    \n    console.log(\\`Found \\${markdownFiles.length} markdown files to process\\`);\n    \n    // Process each file\n    for (const filename of markdownFiles) {\n      const filePath = path.join(directory, filename);\n      const content = await fs.readFile(filePath, 'utf-8');\n      \n      // Create document object\n      const document = {\n        id: path.basename(filename, '.md'),\n        content: content,\n        metadata: {\n          source: filename,\n          type: 'markdown',\n          created: new Date().toISOString(),\n          filename: filename\n        }\n      };\n      \n      console.log(\\`Processing \\${filename}...\\`);\n      \n      // Chunk the document\n      const chunks = await chunker.chunkDocument(document);\n      console.log(\\`Created \\${chunks.length} chunks from \\${filename}\\`);\n      \n      // Ingest the chunks\n      const result = await rag.ingestBatch(chunks);\n      console.log(\\`Ingested \\${result.processed} chunks from \\${filename}\\`);\n    }\n    \n    console.log('Document ingestion complete!');\n    \n  } catch (error) {\n    console.error('Error ingesting documents:', error);\n  } finally {\n    await rag.close();\n  }\n}\n\n// Main function\nasync function main() {\n  const articlesDir = path.join(__dirname, '../data/articles');\n  \n  console.log('Starting document ingestion...');\n  console.log(\\`Using \\${config.chunking.strategy} chunking strategy\\`);\n  console.log(\\`Max chunk size: \\${config.chunking.maxChunkSize} characters\\`);\n  console.log(\\`Chunk overlap: \\${config.chunking.overlap} characters\\`);\n  \n  await rag.connect();\n  await ingestMarkdownFiles(articlesDir);\n}\n\n// Run the ingestion process\nmain().catch(console.error);\nEOL\n\n# Create vector search script\ncat <<EOL > rag-workshop/src/search.js\nconst { MongoRAG } = require('mongodb-rag');\nconst config = require('./config');\n\n// Initialize MongoRAG\nconst rag = new MongoRAG({\n  mongoUrl: config.mongodb.uri,\n  database: config.mongodb.database,\n  collection: config.mongodb.collection,\n  embedding: config.embedding,\n  search: {\n    maxResults: config.search.maxResults,\n    minScore: config.search.minScore\n  }\n});\n\n/**\n * Search for documents relevant to a query\n * @param {string} query - The search query\n * @param {Object} options - Search options\n * @returns {Promise<Array>} - Search results\n */\nasync function searchDocuments(query, options = {}) {\n  try {\n    await rag.connect();\n    \n    console.log(\\`Searching for: \"\\${query}\"\\`);\n    const results = await rag.search(query, {\n      maxResults: options.maxResults || config.search.maxResults,\n      filter: options.filter || {}\n    });\n    \n    // Post-process results if needed\n    const processedResults = results.map(result => {\n      // Add source document if returnSources is enabled\n      if (config.search.returnSources) {\n        return {\n          ...result,\n          source: result.metadata?.filename || 'unknown'\n        };\n      }\n      return result;\n    });\n    \n    return processedResults;\n    \n  } catch (error) {\n    console.error('Search error:', error);\n    throw error;\n  } finally {\n    await rag.close();\n  }\n}\n\n// Export for use in other modules\nmodule.exports = {\n  searchDocuments\n};\n\n// If run directly, perform a test search\nif (require.main === module) {\n  const testQuery = process.argv[2] || 'What is MongoDB Atlas?';\n  \n  searchDocuments(testQuery)\n    .then(results => {\n      console.log(\\`Found \\${results.length} results:\\`);\n      results.forEach((result, i) => {\n        console.log(\\`\\nResult \\${i+1} (score: \\${result.score.toFixed(4)}):\\`);\n        console.log(\\`Source: \\${result.source}\\`);\n        console.log(\\`Content: \\${result.content.substring(0, 150)}...\\`);\n      });\n    })\n    .catch(console.error);\n}\nEOL\n\n# Create LLM response generation script\ncat <<EOL > rag-workshop/src/generate.js\nconst { OpenAI } = require('openai');\nconst config = require('./config');\nconst { searchDocuments } = require('./search');\n\n// Initialize OpenAI client\nconst openai = new OpenAI({\n  apiKey: config.llm.apiKey\n});\n\n/**\n * Generate a response using RAG\n * @param {string} query - User query\n * @param {Object} options - Generation options\n * @returns {Promise<Object>} - Generated response and metadata\n */\nasync function generateResponse(query, options = {}) {\n  try {\n    // Step 1: Retrieve relevant documents\n    const searchResults = await searchDocuments(query, {\n      maxResults: options.maxResults || 3\n    });\n    \n    if (searchResults.length === 0) {\n      return {\n        answer: \"I couldn't find any relevant information to answer your question.\",\n        sources: []\n      };\n    }\n    \n    // Step 2: Format context from retrieved documents\n    const context = searchResults\n      .map(result => \\`Source: \\${result.source}\\\\nContent: \\${result.content}\\`)\n      .join('\\\\n\\\\n');\n    \n    // Step 3: Create prompt with context\n    const messages = [\n      {\n        role: 'system',\n        content: \\`You are a helpful assistant. Answer the user's question based ONLY on the provided context. \n                 If the context doesn't contain relevant information, say \"I don't have enough information to answer that question.\"\n                 Always cite your sources at the end of your answer.\\`\n      },\n      {\n        role: 'user',\n        content: \\`Context:\\\\n\\${context}\\\\n\\\\nQuestion: \\${query}\\`\n      }\n    ];\n    \n    // Step 4: Generate response using LLM\n    const completion = await openai.chat.completions.create({\n      model: config.llm.model,\n      messages: messages,\n      temperature: options.temperature || 0.3,\n      max_tokens: options.maxTokens || 500\n    });\n    \n    // Step 5: Return formatted response with sources\n    return {\n      answer: completion.choices[0].message.content,\n      sources: searchResults.map(result => ({\n        source: result.source,\n        score: result.score\n      }))\n    };\n    \n  } catch (error) {\n    console.error('Error generating response:', error);\n    throw error;\n  }\n}\n\n// Export for use in other modules\nmodule.exports = {\n  generateResponse\n};\n\n// If run directly, perform a test generation\nif (require.main === module) {\n  const testQuery = process.argv[2] || 'What are the security features of MongoDB Atlas?';\n  \n  generateResponse(testQuery)\n    .then(response => {\n      console.log('\\\\n\ud83e\udd16 Generated Answer:');\n      console.log(response.answer);\n      \n      console.log('\\\\n\ud83d\udcda Sources:');\n      response.sources.forEach((source, i) => {\n        console.log(\\`\\${i+1}. \\${source.source} (relevance: \\${source.score.toFixed(4)})\\`);\n      });\n    })\n    .catch(console.error);\n}\nEOL\n\n# Create main application script\ncat <<EOL > rag-workshop/src/index.js\nconst express = require('express');\nconst fs = require('fs-extra');\nconst path = require('path');\nconst { generateResponse } = require('./generate');\nconst { searchDocuments } = require('./search');\nconst config = require('./config');\n\n// Initialize Express app\nconst app = express();\napp.use(express.json());\napp.use(express.urlencoded({ extended: true }));\n\n// Health check endpoint\napp.get('/healthz', (req, res) => {\n  res.status(200).send('OK');\n});\n\n// Search endpoint\napp.get('/api/search', async (req, res) => {\n  try {\n    const { query, maxResults } = req.query;\n    \n    if (!query) {\n      return res.status(400).json({\n        error: 'Missing required parameter: query'\n      });\n    }\n    \n    const results = await searchDocuments(query, {\n      maxResults: maxResults ? parseInt(maxResults) : undefined\n    });\n    \n    res.json({\n      query,\n      results\n    });\n    \n  } catch (error) {\n    console.error('Search API error:', error);\n    res.status(500).json({\n      error: 'An error occurred during search',\n      message: error.message\n    });\n  }\n});\n\n// RAG endpoint\napp.post('/api/rag', async (req, res) => {\n  try {\n    const { query, options } = req.body;\n    \n    if (!query) {\n      return res.status(400).json({\n        error: 'Missing required parameter: query'\n      });\n    }\n    \n    const response = await generateResponse(query, options);\n    res.json(response);\n    \n  } catch (error) {\n    console.error('RAG API error:', error);\n    res.status(500).json({\n      error: 'An error occurred during response generation',\n      message: error.message\n    });\n  }\n});\n\n// Load and answer test questions\napp.get('/api/test', async (req, res) => {\n  try {\n    const qaFilePath = path.join(__dirname, '../data/qa-pairs.json');\n    const qaData = await fs.readJSON(qaFilePath);\n    \n    const results = [];\n    \n    for (const qa of qaData) {\n      const response = await generateResponse(qa.question);\n      \n      // Check if the expected source appears in the sources\n      const foundExpectedSource = response.sources.some(\n        source => source.source.includes(qa.expected_source)\n      );\n      \n      results.push({\n        question: qa.question,\n        answer: response.answer,\n        expected_source: qa.expected_source,\n        found_expected_source: foundExpectedSource,\n        sources: response.sources\n      });\n    }\n    \n    res.json({\n      total: qaData.length,\n      correct_sources: results.filter(r => r.found_expected_source).length,\n      results\n    });\n    \n  } catch (error) {\n    console.error('Test API error:', error);\n    res.status(500).json({\n      error: 'An error occurred during test',\n      message: error.message\n    });\n  }\n});\n\n// Start the server\nconst PORT = process.env.PORT || 3000;\napp.listen(PORT, () => {\n  console.log(\\`\ud83d\ude80 RAG application server running on port \\${PORT}\\`);\n  console.log(\\`\ud83d\udcdd API Documentation:\\`);\n  console.log(\\`   - GET  /healthz             Health check\\`);\n  console.log(\\`   - GET  /api/search?query=X  Vector search\\`);\n  console.log(\\`   - POST /api/rag              RAG response generation\\`);\n  console.log(\\`   - GET  /api/test             Run test suite\\`);\n});\nEOL\n\n# Create a test script\ncat <<EOL > rag-workshop/tests/app.test.js\nconst request = require('supertest');\nconst app = require('../src/index');\n\ndescribe('RAG Application API', () => {\n  it('should return OK for health check', async () => {\n    const res = await request(app).get('/healthz');\n    expect(res.statusCode).toEqual(200);\n    expect(res.text).toEqual('OK');\n  });\n\n  it('should return search results for a valid query', async () => {\n    const res = await request(app).get('/api/search?query=What%20is%20MongoDB%20Atlas?');\n    expect(res.statusCode).toEqual(200);\n    expect(res.body).toHaveProperty('results');\n  });\n\n  it('should return a response for a valid RAG query', async () => {\n    const res = await request(app)\n      .post('/api/rag')\n      .send({ query: 'What are the security features of MongoDB Atlas?' });\n    expect(res.statusCode).toEqual(200);\n    expect(res.body).toHaveProperty('answer');\n  });\n});\nEOL\n\necho \"Project setup complete. Navigate to the 'rag-workshop' directory and run 'npm install' to install dependencies.\"\n"})})]})}function d(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(l,{...n})}):l(n)}},8453:function(n,e,t){t.d(e,{R:function(){return a},x:function(){return i}});var r=t(6540);const o={},s=r.createContext(o);function a(n){const e=r.useContext(s);return r.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),r.createElement(s.Provider,{value:e},n.children)}}}]);